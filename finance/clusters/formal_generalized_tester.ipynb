{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okayyyy, so here's what we're going for:\n",
    "\n",
    "Null: Fat tails are _uniforimly_ or _normally_ distributed.\n",
    "\n",
    "Alternate: The things appear in big clusters, and specifically, they whip around. \n",
    "\n",
    "Point: If I can prove that a big move(specifically in commodities and volatility) is clustered with/paired with/indicative of a big move in the _opposite_ direction the next day, I serve to make a lot of money. \n",
    "\n",
    "What I don't want: For it to be a *coin flip*. \n",
    "\n",
    "Let's get cracking. \n",
    "\n",
    "What we need to know: \n",
    "- One: Whether these moves are, in fact, clustered.\n",
    "- Two: Whether these moves are, in fact, _usually_ opposite.\n",
    "- Three: Whether these moves are or are not clustered depending on product. \n",
    "- Four: Whether high kurtosis has an effect \n",
    "    (I know it will on the freq of big moves, Idk about the diretionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sc\n",
    "import matplotlib.pyplot as plt\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "import pandas_datareader as pdr\n",
    "from datetime import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grabs data. Creates returns, date and 'mover' (sds to be considered a big move) columns\n",
    "def grab_data(ticker, stdevs, start, end):\n",
    "    ticker = pdr.DataReader(ticker, 'iex', start, end)\n",
    "    dates = pd.to_datetime(ticker.index)\n",
    "    ticker[\"date\"] = dates\n",
    "    ticker['returns'] = (ticker.close - ticker.open)/ticker.open\n",
    "    mover = []\n",
    "    thres = stdevs*np.std(ticker['returns'])\n",
    "    for i in ticker['returns']:\n",
    "        if abs(i) > thres:\n",
    "            mover += [True]\n",
    "        else: \n",
    "            mover += [False]\n",
    "    ticker['mover'] = mover\n",
    "    return ticker\n",
    "\n",
    "#graphs a returns chart, big moves in red\n",
    "def make_graph(ticker):\n",
    "    fig, graph = plt.subplots()\n",
    "    graph.plot_date(ticker.date, ticker.returns)\n",
    "    graph.plot_date(ticker[ticker['mover']].date, ticker[ticker['mover']].returns, c = 'r')\n",
    "    graph.grid()\n",
    "    x1, x2, y1, y2 = graph.axis()\n",
    "    graph.axis([x1, x2, -.3, .3]) #set to remove scale bias\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5y\n",
      "5y\n"
     ]
    }
   ],
   "source": [
    "#setting start/end, etf list, making the etf_database (dict style representation)\n",
    "start = datetime(2013, 11, 16)\n",
    "end = datetime(2018, 11, 15)\n",
    "etfs = ['EWJ', 'USO']\n",
    "etf_database = {}\n",
    "for i in etfs:\n",
    "    etf_database[i] = grab_data(i, 3, start, end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##etf_database['EWJ'].mover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is misleading as singular (cluster)\n",
    "#it returns all the clusters for a given dataframe\n",
    "#n.b. you have to give it a pre-selected dataframe so either \n",
    "#screen or pass in a sample\n",
    "#also, non-clusters are returned as \"clusters\" of one\n",
    "def build_cluster(etf_movers_selected, current_cluster= []):\n",
    "    movers = etf_movers_selected\n",
    "    cluster_list = []\n",
    "    #-1 to avoid index error + irrelavant because you can't know when the next big move is\n",
    "    for i in np.arange(0, len(movers.date) - 1): \n",
    "        move_date = movers['date'][i]\n",
    "        next_move = movers['date'][i +1]\n",
    "        current_cluster += [move_date]\n",
    "        if (next_move - move_date).days <= 5:\n",
    "            current_cluster += [next_move]\n",
    "        else:\n",
    "            cluster_list += [current_cluster]\n",
    "            current_cluster = []\n",
    "    return cluster_list\n",
    "            \n",
    "    \n",
    "#this is an appropriation function\n",
    "#i kid, lowkey it's for a later function, cluster base\n",
    "#gets rid of duplicate dates\n",
    "def get_unique_clusters(etf_cluster, start):\n",
    "    def minus_start(some_date):\n",
    "        return [(i - start).days for i in some_date]  \n",
    "    days = list(map(minus_start, etf_cluster))\n",
    "    unique_days = [list(set(i)) for i in days]\n",
    "    return unique_days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes a database storing all the clusters of a given etf_datbase\n",
    "def make_cluster_base(etf_database):\n",
    "    cluster_base = {}\n",
    "    for i in etf_database.keys():\n",
    "        movers = etf_database[i][etf_database[i]['mover']] #selecting movers for build cluster,\n",
    "        cluster_base[i] = get_unique_clusters(build_cluster(movers), etf_database[i].date[0])\n",
    "    return cluster_base\n",
    "\n",
    "#returns the fraction of clusters in a list of flagged moves, grouped by distance\n",
    "def fraction_cluster(cluster_list):\n",
    "    cluster_count = 0\n",
    "    for cluster in cluster_list:\n",
    "            if len(cluster) != 1:\n",
    "                cluster_count +=1 \n",
    "    return cluster_count/len(cluster_list)\n",
    "\n",
    "#returns a dict of fractions of clusters from a cluster database\n",
    "#essentitally, this a databse for observed values (and later resampled ones)\n",
    "def get_cluster_fracs(cluster_database):\n",
    "    fraction_clusters = {}\n",
    "    for name in cluster_database:\n",
    "        frac_cluster = fraction_cluster(cluster_database[name]) \n",
    "        fraction_clusters[name] = frac_cluster\n",
    "    return fraction_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a bitch to run but that's okay\n",
    "#grabs you resamapled data of some dataframe based on how many movers there were\n",
    "#so it's set, more or less, at the data grabbing level\n",
    "#has repetitions and sample size included\n",
    "def get_resampled_data(etf_database, repetitions = 100, sample_size = 30):\n",
    "    resampled_data_dict = {}\n",
    "    for i in etf_database.keys():\n",
    "        resampled_data = []\n",
    "        for j in np.arange(repetitions):\n",
    "            sample_clusters_to_mean = []\n",
    "            for k in np.arange(sample_size):\n",
    "                ticker = etf_database[i]\n",
    "                resampled_df = ticker.sample(len(ticker[ticker['mover']]))\n",
    "                resampled_df_sorted = resampled_df.sort_index()\n",
    "                resampled_cluster = build_cluster(resampled_df_sorted)\n",
    "                sample_clusters_to_mean += [fraction_cluster(resampled_cluster)]\n",
    "            resampled_data += [np.mean(sample_clusters_to_mean)]\n",
    "        resampled_data_dict[i] = resampled_data\n",
    "    return resampled_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this takes in a database of etf dataframes as defined far above and a sample data database\n",
    "#outputs a bunch of graphs proving your hypothsis (it's okay popper, this is acceptable)\n",
    "#also has another txt file output (look at those numbers karl; look at those numbers KARL)\n",
    "def make_cluster_graph(etf_database, sample_database):\n",
    "    cluster_baser = make_cluster_base(etf_database)\n",
    "    observed = get_cluster_fracs(cluster_baser)\n",
    "    txter = open('analysis/v_important_cluster_analysis', 'w+')\n",
    "    for i in etf_database.keys():\n",
    "        resampled_data = sample_database[i]\n",
    "        plt.axvline(np.percentile(resampled_data, .5), color = 'purple', marker = '|')\n",
    "        plt.axvline(np.percentile(resampled_data, 99.5), color = 'purple', marker = '|')\n",
    "        plt.axvline(observed[i], color = 'red')\n",
    "        plt.hist(np.array(resampled_data), bins = 17)\n",
    "        plt.xlabel('Fraction Clustered')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Clusters of ' + str(i))\n",
    "        plt.grid()\n",
    "        plt.text(0.25, -4, \"Purple is 99% confidence at random; Red is the observed.\", ha = 'center')\n",
    "        stds = np.round(observed[i]/np.std(resampled_data), 2)\n",
    "        text = \"That's \" + str(stds) + \" standard deviations away, in case you were wondering.\"\n",
    "        plt.text(0.25, -5.3, text , ha = 'center')\n",
    "        clusterimgfilename = ('images/'+ i + 'clusterchart.png')\n",
    "        plt.savefig(clusterimgfilename, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        text = \"{}: The observed percentage of clusters, {}%, for {} was {} standard deviations from the mean value of {}%.\".format(i, 100*np.round(observed[i], 4), i, stds, 100*np.round(np.mean(resampled_data), 4))\n",
    "        txter.write(text + \"\\n\\n\")\n",
    "    txter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tying it all together for hypothesis test number one\n",
    "sample_database_forever = get_resampled_data(etf_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_cluster_graph(etf_database, sample_database_forever)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
